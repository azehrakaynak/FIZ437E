{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP-image_classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**MLP with IMAGE CLASSIFICATION**"
      ],
      "metadata": {
        "id": "jyvgTUdat6oc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "v7du5NnGt5qE"
      },
      "outputs": [],
      "source": [
        "import copy \n",
        "import random\n",
        "import time\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn import metrics\n",
        "from sklearn import decomposition\n",
        "from sklearn import manifold\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now we created Dataset.**"
      ],
      "metadata": {
        "id": "Vasx68D1uGFA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 classes : \n",
        "          Drone\n",
        "          Airplane\n",
        "          Helicopter"
      ],
      "metadata": {
        "id": "asp11caSuKjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Oluşturduğumuz dataseti drive'a yükledik. Drive'dan google colab'e çekmek için kullanmamız gereken\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgEWXh50uM6L",
        "outputId": "924b356f-a90d-4c59-82c0-b94ca3afe866"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#yüklediğimiz zip dosya uzantılı dataseti zip'ten çıkarmak için \n",
        "!unzip -q /content/drive/MyDrive/FIZ437E/Sky-Dataset.zip -d ../"
      ],
      "metadata": {
        "id": "YMV3y268uUBb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_dataset = '/content/drive/MyDrive/FIZ437E/sky-Dataset'"
      ],
      "metadata": {
        "id": "_BX-yUAIvJO1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_ = torch.tensor([0.490, 0.460, 0.40], dtype=torch.float32)\n",
        "std_ = torch.tensor([0.230, 0.220, 0.223], dtype=torch.float32)\n",
        "\n",
        "transform = transforms.Compose([transforms.RandomRotation(5),\n",
        "                                transforms.Resize(256),\n",
        "                                transforms.RandomCrop(256, padding=5),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=mean_, std=std_)\n",
        "])\n",
        "\n",
        "DATASET = torchvision.datasets.ImageFolder(path_dataset, \n",
        "                                           transform=transform)\n",
        "\n",
        "#datasetimizin %85'i train %15 i validation olsun.\n",
        "len_dataset = len(DATASET)\n",
        "len_train = round(len(DATASET)*(0.85))\n",
        "len_validation = round(len(DATASET)*(0.15))\n",
        "\n",
        "print('Number of all examples: ',len_dataset)\n",
        "print('Number of training examples: ',len_train)\n",
        "print('Number of testing examples: ',len_validation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZzu5CF-vPlf",
        "outputId": "187b7ff7-75d3-4936-e4a8-5c49f55be6d2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of all examples:  5599\n",
            "Number of training examples:  4759\n",
            "Number of testing examples:  840\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, test_dataset = torch.utils.data.random_split(DATASET, (len_train, len_validation))\n",
        "\n",
        "train_data = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                              batch_size=24,     # (number of classes + 5 )* 3\n",
        "                                              shuffle=True,\n",
        ")\n",
        "\n",
        "test_data = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                              batch_size=24,\n",
        "                                              shuffle=False,\n",
        ")"
      ],
      "metadata": {
        "id": "t4oyMJk9vTk0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining MLP Model**"
      ],
      "metadata": {
        "id": "UOOQ3EJkvXZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super().__init__()\n",
        "                \n",
        "        self.input_fc = nn.Linear(input_dim, 15)\n",
        "        self.hidden_fc = nn.Linear(15, 12)\n",
        "        self.output_fc = nn.Linear(12, output_dim)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        #x = [batch size, height, width]\n",
        "        \n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        x = x.view(batch_size, -1)\n",
        "        \n",
        "        #x = [batch size, height * width]\n",
        "        \n",
        "        h_1 = F.relu(self.input_fc(x))\n",
        "        \n",
        "        #h_1 = [batch size, 250]\n",
        "\n",
        "        h_2 = F.relu(self.hidden_fc(h_1))\n",
        "\n",
        "        #h_2 = [batch size, 100]\n",
        "\n",
        "        y_pred = self.output_fc(h_2)\n",
        "        \n",
        "        #y_pred = [batch size, output dim]\n",
        "        \n",
        "        return y_pred, h_2"
      ],
      "metadata": {
        "id": "cks6Qw8hvYST"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dimension = 256 * 256* 3\n",
        "output_dimension = 10\n",
        "\n",
        "model = MLP(input_dimension, output_dimension)"
      ],
      "metadata": {
        "id": "I77_Ql7ZvcJs"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimization  and Loss Function"
      ],
      "metadata": {
        "id": "MyRE9qsBvekz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "#create cross entropy\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def calculate_accuracy(y_pred, y):\n",
        "    top_pred = y_pred.argmax(1, keepdim = True)\n",
        "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
        "    acc = correct.float() / y.shape[0]\n",
        "    return acc\n"
      ],
      "metadata": {
        "id": "b3YUrxgYvfEI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Function"
      ],
      "metadata": {
        "id": "erleW218vlq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion,epoch):\n",
        "    \n",
        "    epoch_loss_train = 0\n",
        "    epoch_accuracy_train = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for i,(x, y) in enumerate(iterator):\n",
        "      \n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "                \n",
        "        y_pred, _ = model(x)\n",
        "        \n",
        "        loss = criterion(y_pred, y)\n",
        "        \n",
        "        acc = calculate_accuracy(y_pred, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss_train += loss.item()\n",
        "        epoch_accuracy_train += acc.item()\n",
        "\n",
        "        if i%40 == 0:\n",
        "            print('Epoch: [{}]/({}/{}), Train Loss: {:.4f}, Accuracy: {:.2f}'.format(\n",
        "                epoch, i,len(train_data),loss.item(), epoch_accuracy_train / len(iterator)))\n",
        "        \n",
        "    return epoch_loss_train / len(iterator), epoch_accuracy_train / len(iterator)"
      ],
      "metadata": {
        "id": "t9gRDX5lvnQ4"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Function"
      ],
      "metadata": {
        "id": "6JVkOMQYvrQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    epoch_loss_test = 0\n",
        "    epoch_accuracy_test = 0\n",
        "      \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        \n",
        "        for (x, y) in iterator:\n",
        "\n",
        "            y_pred, _ = model(x)\n",
        "\n",
        "            loss = criterion(y_pred, y)\n",
        "\n",
        "            acc = calculate_accuracy(y_pred, y)\n",
        "\n",
        "            epoch_loss_test += loss.item()\n",
        "            epoch_accuracy_test += acc.item()\n",
        "\n",
        "    print('Epoch: [{}], Test Loss: {:.4f}, Accuracy: {:.2f}'.format(\n",
        "    epoch, epoch_loss_test / len(iterator), epoch_accuracy_test / len(iterator)))\n",
        "        \n",
        "    return epoch_loss_test / len(iterator), epoch_accuracy_test / len(iterator)"
      ],
      "metadata": {
        "id": "z6yQ2kx7vrm-"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training the Model**"
      ],
      "metadata": {
        "id": "f7WjVfTDvvKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Epochs = 30\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(Epochs):   \n",
        "    \n",
        "    train_loss, train_acc = train(model, train_data, optimizer, criterion,epoch)\n",
        "    valid_loss, valid_acc = evaluate(model, test_data, criterion)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'model.pt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lVSXDxsJvyQz",
        "outputId": "30760ba5-c205-4302-e42b-0e1bf90fa2d0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: [0]/(0/199), Train Loss: 2.2135, Accuracy: 0.00\n",
            "Epoch: [0]/(40/199), Train Loss: 2.3549, Accuracy: 0.16\n",
            "Epoch: [0]/(80/199), Train Loss: 1.4119, Accuracy: 0.32\n",
            "Epoch: [0]/(120/199), Train Loss: 0.2563, Accuracy: 0.49\n",
            "Epoch: [0]/(160/199), Train Loss: 0.7786, Accuracy: 0.65\n",
            "Epoch: [0], Test Loss: 0.5696, Accuracy: 0.86\n",
            "Epoch: [1]/(0/199), Train Loss: 0.4373, Accuracy: 0.00\n",
            "Epoch: [1]/(40/199), Train Loss: 0.3739, Accuracy: 0.18\n",
            "Epoch: [1]/(80/199), Train Loss: 0.4677, Accuracy: 0.35\n",
            "Epoch: [1]/(120/199), Train Loss: 0.3429, Accuracy: 0.51\n",
            "Epoch: [1]/(160/199), Train Loss: 0.0664, Accuracy: 0.69\n",
            "Epoch: [1], Test Loss: 0.5442, Accuracy: 0.87\n",
            "Epoch: [2]/(0/199), Train Loss: 3.0562, Accuracy: 0.00\n",
            "Epoch: [2]/(40/199), Train Loss: 0.3336, Accuracy: 0.17\n",
            "Epoch: [2]/(80/199), Train Loss: 0.8463, Accuracy: 0.35\n",
            "Epoch: [2]/(120/199), Train Loss: 0.1551, Accuracy: 0.52\n",
            "Epoch: [2]/(160/199), Train Loss: 0.7276, Accuracy: 0.69\n",
            "Epoch: [2], Test Loss: 0.6343, Accuracy: 0.87\n",
            "Epoch: [3]/(0/199), Train Loss: 0.4184, Accuracy: 0.00\n",
            "Epoch: [3]/(40/199), Train Loss: 0.4060, Accuracy: 0.18\n",
            "Epoch: [3]/(80/199), Train Loss: 0.2718, Accuracy: 0.35\n",
            "Epoch: [3]/(120/199), Train Loss: 0.2299, Accuracy: 0.53\n",
            "Epoch: [3]/(160/199), Train Loss: 0.4876, Accuracy: 0.70\n",
            "Epoch: [3], Test Loss: 0.4728, Accuracy: 0.90\n",
            "Epoch: [4]/(0/199), Train Loss: 0.3154, Accuracy: 0.00\n",
            "Epoch: [4]/(40/199), Train Loss: 0.3162, Accuracy: 0.18\n",
            "Epoch: [4]/(80/199), Train Loss: 0.6441, Accuracy: 0.35\n",
            "Epoch: [4]/(120/199), Train Loss: 0.5112, Accuracy: 0.53\n",
            "Epoch: [4]/(160/199), Train Loss: 0.4941, Accuracy: 0.70\n",
            "Epoch: [4], Test Loss: 0.3996, Accuracy: 0.89\n",
            "Epoch: [5]/(0/199), Train Loss: 0.4300, Accuracy: 0.00\n",
            "Epoch: [5]/(40/199), Train Loss: 0.2767, Accuracy: 0.18\n",
            "Epoch: [5]/(80/199), Train Loss: 0.5926, Accuracy: 0.35\n",
            "Epoch: [5]/(120/199), Train Loss: 0.3303, Accuracy: 0.53\n",
            "Epoch: [5]/(160/199), Train Loss: 0.3191, Accuracy: 0.70\n",
            "Epoch: [5], Test Loss: 0.3604, Accuracy: 0.90\n",
            "Epoch: [6]/(0/199), Train Loss: 0.2898, Accuracy: 0.00\n",
            "Epoch: [6]/(40/199), Train Loss: 0.6035, Accuracy: 0.18\n",
            "Epoch: [6]/(80/199), Train Loss: 0.5621, Accuracy: 0.36\n",
            "Epoch: [6]/(120/199), Train Loss: 0.1108, Accuracy: 0.54\n",
            "Epoch: [6]/(160/199), Train Loss: 0.3951, Accuracy: 0.71\n",
            "Epoch: [6], Test Loss: 0.3544, Accuracy: 0.89\n",
            "Epoch: [7]/(0/199), Train Loss: 0.5503, Accuracy: 0.00\n",
            "Epoch: [7]/(40/199), Train Loss: 0.3307, Accuracy: 0.18\n",
            "Epoch: [7]/(80/199), Train Loss: 0.4374, Accuracy: 0.36\n",
            "Epoch: [7]/(120/199), Train Loss: 0.1704, Accuracy: 0.53\n",
            "Epoch: [7]/(160/199), Train Loss: 0.4323, Accuracy: 0.71\n",
            "Epoch: [7], Test Loss: 0.3612, Accuracy: 0.89\n",
            "Epoch: [8]/(0/199), Train Loss: 0.3106, Accuracy: 0.00\n",
            "Epoch: [8]/(40/199), Train Loss: 0.4020, Accuracy: 0.18\n",
            "Epoch: [8]/(80/199), Train Loss: 0.3594, Accuracy: 0.36\n",
            "Epoch: [8]/(120/199), Train Loss: 0.4545, Accuracy: 0.53\n",
            "Epoch: [8]/(160/199), Train Loss: 0.3924, Accuracy: 0.70\n",
            "Epoch: [8], Test Loss: 0.3781, Accuracy: 0.90\n",
            "Epoch: [9]/(0/199), Train Loss: 0.4617, Accuracy: 0.00\n",
            "Epoch: [9]/(40/199), Train Loss: 0.4774, Accuracy: 0.18\n",
            "Epoch: [9]/(80/199), Train Loss: 0.3892, Accuracy: 0.36\n",
            "Epoch: [9]/(120/199), Train Loss: 0.2801, Accuracy: 0.53\n",
            "Epoch: [9]/(160/199), Train Loss: 0.1209, Accuracy: 0.71\n",
            "Epoch: [9], Test Loss: 0.3399, Accuracy: 0.90\n",
            "Epoch: [10]/(0/199), Train Loss: 0.6533, Accuracy: 0.00\n",
            "Epoch: [10]/(40/199), Train Loss: 0.2447, Accuracy: 0.18\n",
            "Epoch: [10]/(80/199), Train Loss: 0.5134, Accuracy: 0.36\n",
            "Epoch: [10]/(120/199), Train Loss: 0.3100, Accuracy: 0.53\n",
            "Epoch: [10]/(160/199), Train Loss: 0.3125, Accuracy: 0.71\n",
            "Epoch: [10], Test Loss: 0.3828, Accuracy: 0.90\n",
            "Epoch: [11]/(0/199), Train Loss: 0.1923, Accuracy: 0.00\n",
            "Epoch: [11]/(40/199), Train Loss: 0.4629, Accuracy: 0.18\n",
            "Epoch: [11]/(80/199), Train Loss: 0.2392, Accuracy: 0.35\n",
            "Epoch: [11]/(120/199), Train Loss: 0.4006, Accuracy: 0.53\n",
            "Epoch: [11]/(160/199), Train Loss: 0.5395, Accuracy: 0.71\n",
            "Epoch: [11], Test Loss: 0.4278, Accuracy: 0.90\n",
            "Epoch: [12]/(0/199), Train Loss: 0.0302, Accuracy: 0.01\n",
            "Epoch: [12]/(40/199), Train Loss: 0.2990, Accuracy: 0.18\n",
            "Epoch: [12]/(80/199), Train Loss: 0.3662, Accuracy: 0.36\n",
            "Epoch: [12]/(120/199), Train Loss: 0.3351, Accuracy: 0.53\n",
            "Epoch: [12]/(160/199), Train Loss: 0.2487, Accuracy: 0.71\n",
            "Epoch: [12], Test Loss: 0.3448, Accuracy: 0.90\n",
            "Epoch: [13]/(0/199), Train Loss: 0.2981, Accuracy: 0.00\n",
            "Epoch: [13]/(40/199), Train Loss: 0.2376, Accuracy: 0.18\n",
            "Epoch: [13]/(80/199), Train Loss: 0.5075, Accuracy: 0.35\n",
            "Epoch: [13]/(120/199), Train Loss: 0.3011, Accuracy: 0.53\n",
            "Epoch: [13]/(160/199), Train Loss: 0.3456, Accuracy: 0.70\n",
            "Epoch: [13], Test Loss: 0.3841, Accuracy: 0.90\n",
            "Epoch: [14]/(0/199), Train Loss: 0.1843, Accuracy: 0.00\n",
            "Epoch: [14]/(40/199), Train Loss: 0.4129, Accuracy: 0.18\n",
            "Epoch: [14]/(80/199), Train Loss: 0.4624, Accuracy: 0.36\n",
            "Epoch: [14]/(120/199), Train Loss: 0.5206, Accuracy: 0.53\n",
            "Epoch: [14]/(160/199), Train Loss: 0.1868, Accuracy: 0.71\n",
            "Epoch: [14], Test Loss: 0.3502, Accuracy: 0.90\n",
            "Epoch: [15]/(0/199), Train Loss: 0.4091, Accuracy: 0.00\n",
            "Epoch: [15]/(40/199), Train Loss: 0.4635, Accuracy: 0.18\n",
            "Epoch: [15]/(80/199), Train Loss: 0.5209, Accuracy: 0.36\n",
            "Epoch: [15]/(120/199), Train Loss: 0.2805, Accuracy: 0.53\n",
            "Epoch: [15]/(160/199), Train Loss: 0.2735, Accuracy: 0.71\n",
            "Epoch: [15], Test Loss: 0.3663, Accuracy: 0.90\n",
            "Epoch: [16]/(0/199), Train Loss: 0.2524, Accuracy: 0.00\n",
            "Epoch: [16]/(40/199), Train Loss: 0.2912, Accuracy: 0.18\n",
            "Epoch: [16]/(80/199), Train Loss: 0.6957, Accuracy: 0.36\n",
            "Epoch: [16]/(120/199), Train Loss: 0.3135, Accuracy: 0.53\n",
            "Epoch: [16]/(160/199), Train Loss: 0.4947, Accuracy: 0.71\n",
            "Epoch: [16], Test Loss: 0.3340, Accuracy: 0.90\n",
            "Epoch: [17]/(0/199), Train Loss: 0.4076, Accuracy: 0.00\n",
            "Epoch: [17]/(40/199), Train Loss: 0.5401, Accuracy: 0.18\n",
            "Epoch: [17]/(80/199), Train Loss: 0.2695, Accuracy: 0.36\n",
            "Epoch: [17]/(120/199), Train Loss: 0.1930, Accuracy: 0.53\n",
            "Epoch: [17]/(160/199), Train Loss: 0.5823, Accuracy: 0.71\n",
            "Epoch: [17], Test Loss: 0.3476, Accuracy: 0.89\n",
            "Epoch: [18]/(0/199), Train Loss: 0.2908, Accuracy: 0.00\n",
            "Epoch: [18]/(40/199), Train Loss: 0.5908, Accuracy: 0.18\n",
            "Epoch: [18]/(80/199), Train Loss: 0.1063, Accuracy: 0.36\n",
            "Epoch: [18]/(120/199), Train Loss: 0.2642, Accuracy: 0.53\n",
            "Epoch: [18]/(160/199), Train Loss: 0.3447, Accuracy: 0.71\n",
            "Epoch: [18], Test Loss: 0.3625, Accuracy: 0.90\n",
            "Epoch: [19]/(0/199), Train Loss: 0.2507, Accuracy: 0.01\n",
            "Epoch: [19]/(40/199), Train Loss: 0.5050, Accuracy: 0.18\n",
            "Epoch: [19]/(80/199), Train Loss: 0.4890, Accuracy: 0.36\n",
            "Epoch: [19]/(120/199), Train Loss: 0.5187, Accuracy: 0.53\n",
            "Epoch: [19]/(160/199), Train Loss: 0.3658, Accuracy: 0.71\n",
            "Epoch: [19], Test Loss: 0.3229, Accuracy: 0.90\n",
            "Epoch: [20]/(0/199), Train Loss: 0.2577, Accuracy: 0.00\n",
            "Epoch: [20]/(40/199), Train Loss: 0.3063, Accuracy: 0.18\n",
            "Epoch: [20]/(80/199), Train Loss: 0.2858, Accuracy: 0.36\n",
            "Epoch: [20]/(120/199), Train Loss: 0.4364, Accuracy: 0.53\n",
            "Epoch: [20]/(160/199), Train Loss: 0.1291, Accuracy: 0.71\n",
            "Epoch: [20], Test Loss: 0.3733, Accuracy: 0.90\n",
            "Epoch: [21]/(0/199), Train Loss: 0.5454, Accuracy: 0.00\n",
            "Epoch: [21]/(40/199), Train Loss: 0.4468, Accuracy: 0.18\n",
            "Epoch: [21]/(80/199), Train Loss: 0.6459, Accuracy: 0.36\n",
            "Epoch: [21]/(120/199), Train Loss: 0.2674, Accuracy: 0.54\n",
            "Epoch: [21]/(160/199), Train Loss: 0.1959, Accuracy: 0.71\n",
            "Epoch: [21], Test Loss: 0.3179, Accuracy: 0.90\n",
            "Epoch: [22]/(0/199), Train Loss: 0.5132, Accuracy: 0.00\n",
            "Epoch: [22]/(40/199), Train Loss: 0.4464, Accuracy: 0.18\n",
            "Epoch: [22]/(80/199), Train Loss: 0.2684, Accuracy: 0.36\n",
            "Epoch: [22]/(120/199), Train Loss: 0.3859, Accuracy: 0.53\n",
            "Epoch: [22]/(160/199), Train Loss: 0.6520, Accuracy: 0.71\n",
            "Epoch: [22], Test Loss: 0.3275, Accuracy: 0.90\n",
            "Epoch: [23]/(0/199), Train Loss: 0.4030, Accuracy: 0.00\n",
            "Epoch: [23]/(40/199), Train Loss: 0.0537, Accuracy: 0.18\n",
            "Epoch: [23]/(80/199), Train Loss: 0.1730, Accuracy: 0.36\n",
            "Epoch: [23]/(120/199), Train Loss: 0.2889, Accuracy: 0.53\n",
            "Epoch: [23]/(160/199), Train Loss: 0.2927, Accuracy: 0.71\n",
            "Epoch: [23], Test Loss: 0.3721, Accuracy: 0.88\n",
            "Epoch: [24]/(0/199), Train Loss: 0.4537, Accuracy: 0.00\n",
            "Epoch: [24]/(40/199), Train Loss: 0.3357, Accuracy: 0.18\n",
            "Epoch: [24]/(80/199), Train Loss: 0.2846, Accuracy: 0.35\n",
            "Epoch: [24]/(120/199), Train Loss: 0.1831, Accuracy: 0.53\n",
            "Epoch: [24]/(160/199), Train Loss: 0.2393, Accuracy: 0.71\n",
            "Epoch: [24], Test Loss: 0.3246, Accuracy: 0.90\n",
            "Epoch: [25]/(0/199), Train Loss: 0.4919, Accuracy: 0.00\n",
            "Epoch: [25]/(40/199), Train Loss: 0.2814, Accuracy: 0.18\n",
            "Epoch: [25]/(80/199), Train Loss: 0.5673, Accuracy: 0.36\n",
            "Epoch: [25]/(120/199), Train Loss: 0.4815, Accuracy: 0.53\n",
            "Epoch: [25]/(160/199), Train Loss: 0.2903, Accuracy: 0.71\n",
            "Epoch: [25], Test Loss: 0.3627, Accuracy: 0.90\n",
            "Epoch: [26]/(0/199), Train Loss: 0.5841, Accuracy: 0.00\n",
            "Epoch: [26]/(40/199), Train Loss: 0.2461, Accuracy: 0.18\n",
            "Epoch: [26]/(80/199), Train Loss: 0.2184, Accuracy: 0.36\n",
            "Epoch: [26]/(120/199), Train Loss: 0.4380, Accuracy: 0.54\n",
            "Epoch: [26]/(160/199), Train Loss: 0.5505, Accuracy: 0.71\n",
            "Epoch: [26], Test Loss: 0.3261, Accuracy: 0.90\n",
            "Epoch: [27]/(0/199), Train Loss: 0.4537, Accuracy: 0.00\n",
            "Epoch: [27]/(40/199), Train Loss: 0.5722, Accuracy: 0.18\n",
            "Epoch: [27]/(80/199), Train Loss: 0.2121, Accuracy: 0.35\n",
            "Epoch: [27]/(120/199), Train Loss: 0.5456, Accuracy: 0.53\n",
            "Epoch: [27]/(160/199), Train Loss: 0.3594, Accuracy: 0.71\n",
            "Epoch: [27], Test Loss: 0.3219, Accuracy: 0.90\n",
            "Epoch: [28]/(0/199), Train Loss: 0.2883, Accuracy: 0.00\n",
            "Epoch: [28]/(40/199), Train Loss: 0.3511, Accuracy: 0.18\n",
            "Epoch: [28]/(80/199), Train Loss: 0.3051, Accuracy: 0.36\n",
            "Epoch: [28]/(120/199), Train Loss: 0.3288, Accuracy: 0.54\n",
            "Epoch: [28]/(160/199), Train Loss: 0.2282, Accuracy: 0.71\n",
            "Epoch: [28], Test Loss: 0.3196, Accuracy: 0.90\n",
            "Epoch: [29]/(0/199), Train Loss: 0.3946, Accuracy: 0.00\n",
            "Epoch: [29]/(40/199), Train Loss: 0.4756, Accuracy: 0.18\n",
            "Epoch: [29]/(80/199), Train Loss: 0.3984, Accuracy: 0.36\n",
            "Epoch: [29]/(120/199), Train Loss: 0.4348, Accuracy: 0.53\n",
            "Epoch: [29]/(160/199), Train Loss: 0.4774, Accuracy: 0.71\n",
            "Epoch: [29], Test Loss: 0.3466, Accuracy: 0.90\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n    print(f'Epoch: {epoch+1:02}')\\n    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\\n    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\\n    \""
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss of MLP Model :  0.3466"
      ],
      "metadata": {
        "id": "sb8RZD0PuGN2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy of MLP Model : %90"
      ],
      "metadata": {
        "id": "gtOeQAqBuMF-"
      }
    }
  ]
}